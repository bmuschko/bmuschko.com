<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>build on Benjamin Muschko&#39;s development blog</title>
    <link>https://bmuschko.com/tags/build/</link>
    <description>Recent content in build on Benjamin Muschko&#39;s development blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 01 Feb 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://bmuschko.com/tags/build/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Building Groovy with Bazel</title>
      <link>https://bmuschko.com/blog/bazel-groovy/</link>
      <pubDate>Sat, 01 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bmuschko.com/blog/bazel-groovy/</guid>
      <description>Bazel is a build automation tool that ships with support for a variety of languages out-of-the-box. For example, you can build Java projects right away without having to configure external functionality, so-called rules. Groovy is a popular language in the JVM space. As a developer, you’d expect the following features:
   Compiling Groovy source code
  Creating a JAR file to bundle the class files
  Executing Groovy-based tests written with JUnit or Spock</description>
    </item>
    
    <item>
      <title>Best practices for writing Jenkins shared libraries</title>
      <link>https://bmuschko.com/blog/jenkins-shared-libraries/</link>
      <pubDate>Thu, 31 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://bmuschko.com/blog/jenkins-shared-libraries/</guid>
      <description>Introduction Pipeline definitions in Jenkins start small and maintainble. You write a Jenkinsfile that declares a couple of stages. Nothing dramatic, simple, understandable code. As your adoption of Jenkins and &amp;#34;pipelines as code&amp;#34; grows within the organization, you’ll find out that other teams are copy-pasting pipeline code all over the place. What works for one project should work for other projects, right?! Soon requirements become more complex and your organization will enter a world of pain of unmaintainable, duplicated code.</description>
    </item>
    
    <item>
      <title>Containerization workflow for Java apps with Jib</title>
      <link>https://bmuschko.com/blog/containerization-with-jib/</link>
      <pubDate>Tue, 16 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://bmuschko.com/blog/containerization-with-jib/</guid>
      <description>Containerizing a Java application is the natural extension to building a plain, executable JAR file: &amp;#34;write once, run everywhere&amp;#34;. Creating an optimized image for an application is far from straightforward and requires in-depth knowledge of Docker concepts and best practices.
 A typical developer worflow involves the following steps. First, you start out by writing a Dockerfile with the goal of producing an image small in size while at the same time ensuring cacheability of layers as much as possible.</description>
    </item>
    
    <item>
      <title>Implementing an intuitive versioning and release strategy</title>
      <link>https://bmuschko.com/blog/gradle-release-strategy/</link>
      <pubDate>Thu, 17 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://bmuschko.com/blog/gradle-release-strategy/</guid>
      <description>Implementing a versioning and release strategy for a project can be daunting task. An effective strategy should be elegant and require little manual intervention. When forming a strategy the following factors need to be taken under consideration.
   What kind of artifact(s) does your project produce? Maybe you are writing a library or a full-fledged application comprised of multiple components.
  How often do you usually release your project?</description>
    </item>
    
    <item>
      <title>Docker with Gradle: Getting started with Docker Compose</title>
      <link>https://bmuschko.com/blog/gradle-docker-compose/</link>
      <pubDate>Fri, 27 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://bmuschko.com/blog/gradle-docker-compose/</guid>
      <description>Docker Compose is a tool for defining and running entire application stacks in containers. Gradle plays well with Docker Compose and can automate the bootstrapping of those containers from the build process. In a previous post, I discussed how to use Gradle to start and stop a Docker container for integration testing. In this blog post, I want to continue the discussion by explaining how to manage multiple containers with Compose.</description>
    </item>
    
    <item>
      <title>Docker with Gradle: Writing a Node.js convention plugin</title>
      <link>https://bmuschko.com/blog/gradle-docker-convention-plugin/</link>
      <pubDate>Wed, 28 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://bmuschko.com/blog/gradle-docker-convention-plugin/</guid>
      <description>The Gradle Docker plugin provides turnkey solutions to common use cases. In the previous blog posts of the series &amp;#34;Docker with Gradle&amp;#34;, we looked at creating a Docker image for a Spring Boot application and how to use the image as fixture for integration testing. If you read the articles, you might have noticed that the plugin capabilities are flexible enough to model different situations. Nevertheless, this approach can easily become tedious if you want to use it across multiple, independent projects.</description>
    </item>
    
    <item>
      <title>Easy Gradle project generation</title>
      <link>https://bmuschko.com/blog/gradle-project-generation/</link>
      <pubDate>Tue, 06 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://bmuschko.com/blog/gradle-project-generation/</guid>
      <description>Having to create a build.gradle file, a settings.gradle file and the necessary project layout manually for ever new Gradle project can be a drag. Gradle provides the build init plugin for generating new projects with different flavors from the command line. The downside of this approach is that you already have to have the Gradle runtime installed on your machine. You will likely also have to look up the right combination of command line options from the user manual.</description>
    </item>
    
    <item>
      <title>Docker with Gradle: Integration testing using containers</title>
      <link>https://bmuschko.com/blog/docker-integration-testing/</link>
      <pubDate>Sun, 18 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://bmuschko.com/blog/docker-integration-testing/</guid>
      <description>In the first blog post on &amp;#34;Docker with Gradle&amp;#34; you learned how to package a Spring Boot application as a Docker image. After verifying that the image works as expected you pushed the image to a registry. Being able to produce and push a new image of an application with every single commit lays the foundation for enabling supplemental automation workflows.
 Integration testing plays an important role in the software development lifecycle to ensure functional and non-functional requirements have been met.</description>
    </item>
    
    <item>
      <title>Docker with Gradle: Dockerizing a Spring Boot application</title>
      <link>https://bmuschko.com/blog/dockerized-spring-boot-app/</link>
      <pubDate>Thu, 08 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://bmuschko.com/blog/dockerized-spring-boot-app/</guid>
      <description>The use of Docker has become widespread among companies big and small for a variety scenarios. Executing Docker from the command line for simple tasks is easy and becomes routine as soon as you get a hang of it. Having to enter Docker commands for a whole workflow can become tedious. It seems obvious that you might want to integrate Docker into an automated process for convenience and reproducibility. Gradle can help with defining and executing such a process with the help of the Docker plugin.</description>
    </item>
    
    <item>
      <title>Build pipelines with Jenkins 2 by example</title>
      <link>https://bmuschko.com/blog/jenkins-build-pipeline/</link>
      <pubDate>Mon, 30 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://bmuschko.com/blog/jenkins-build-pipeline/</guid>
      <description>Introduction Jenkins World 2017 came to a close in late September. Time to revisit the improvements that have been made to the support for build pipelines. I am no stranger to using Jenkins to model a Continuous Delivery pipeline. In the dark ages, you had to construct a pipeline with the help of different Jenkins plugins bit by bit. The approach was highly brittle, inconsistent and full of magical tips and tricks.</description>
    </item>
    
    <item>
      <title>Building Go with Gradle</title>
      <link>https://bmuschko.com/blog/golang-with-gradle/</link>
      <pubDate>Sat, 29 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://bmuschko.com/blog/golang-with-gradle/</guid>
      <description>Introduction In July 2017 Google Go made a big jump on the TIOBE index. It’s now ranked among the top 10 most popular programming languages. With the rise of Moby aka Docker, Kubernetes and InfluxDB the language has become the go-to tool in the DevOps space. The complexity of automating the process of building, assembling and distributing the source code and binaries for any medium- to large-sized project is high. It’s somewhat shocking to see that the predominant tooling of automating in Go is still a mixture of Make files and shell scripts as it can be observed in the Moby and Kubernetes code base.</description>
    </item>
    
  </channel>
</rss>
